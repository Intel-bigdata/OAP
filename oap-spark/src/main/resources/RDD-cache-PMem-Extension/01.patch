From 7c346d17928117d208baec6e8d27e71774467be5 Mon Sep 17 00:00:00 2001
From: yeyuqiang <yuqiang.ye@intel.com>
Date: Mon, 25 May 2020 10:37:13 +0800
Subject: [PATCH] Merge RDD Cache code from branch-2.4.4-oap-0.8

---
 common/unsafe/pom.xml                         |  5 ++
 .../spark/unsafe/memory/MemoryAllocator.java  |  2 +
 .../unsafe/memory/PMemMemoryAllocator.java    | 20 ++++++
 core/pom.xml                                  |  4 ++
 .../org/apache/spark/memory/MemoryMode.java   |  3 +-
 .../scala/org/apache/spark/SparkEnv.scala     | 25 +++++++
 .../apache/spark/memory/MemoryManager.scala   | 20 +++++-
 .../spark/memory/StaticMemoryManager.scala    |  8 +++
 .../spark/memory/StorageMemoryPool.scala      |  1 +
 .../spark/memory/UnifiedMemoryManager.scala   | 13 ++++
 .../apache/spark/storage/BlockManager.scala   |  5 +-
 .../apache/spark/storage/StorageLevel.scala   | 66 ++++++++++++-------
 .../spark/storage/memory/MemoryStore.scala    | 20 ++++--
 .../spark/memory/TestMemoryManager.scala      |  2 +
 .../spark/mllib/clustering/KMeans.scala       |  7 +-
 pom.xml                                       |  7 ++
 16 files changed, 174 insertions(+), 34 deletions(-)
 create mode 100644 common/unsafe/src/main/java/org/apache/spark/unsafe/memory/PMemMemoryAllocator.java

diff --git a/common/unsafe/src/main/java/org/apache/spark/unsafe/memory/MemoryAllocator.java b/common/unsafe/src/main/java/org/apache/spark/unsafe/memory/MemoryAllocator.java
index 7b588681d979..10a168e3805f 100644
--- a/common/unsafe/src/main/java/org/apache/spark/unsafe/memory/MemoryAllocator.java
+++ b/common/unsafe/src/main/java/org/apache/spark/unsafe/memory/MemoryAllocator.java
@@ -41,4 +41,6 @@
   MemoryAllocator UNSAFE = new UnsafeMemoryAllocator();

   MemoryAllocator HEAP = new HeapMemoryAllocator();
+
+  MemoryAllocator PMEM = new PMemMemoryAllocator();
 }
diff --git a/common/unsafe/src/main/java/org/apache/spark/unsafe/memory/PMemMemoryAllocator.java b/common/unsafe/src/main/java/org/apache/spark/unsafe/memory/PMemMemoryAllocator.java
new file mode 100644
index 000000000000..1ffd4f3587bb
--- /dev/null
+++ b/common/unsafe/src/main/java/org/apache/spark/unsafe/memory/PMemMemoryAllocator.java
@@ -0,0 +1,20 @@
+package org.apache.spark.unsafe.memory;
+
+import com.intel.oap.common.unsafe.PersistentMemoryPlatform;
+
+public class PMemMemoryAllocator implements MemoryAllocator {
+
+    @Override
+    public MemoryBlock allocate(long size) throws OutOfMemoryError {
+        long address = PersistentMemoryPlatform.allocateVolatileMemory(size);
+        MemoryBlock memoryBlock = new MemoryBlock(null, address, size);
+        return memoryBlock;
+    }
+
+    @Override
+    public void free(MemoryBlock memory) {
+        assert (memory.getBaseObject() == null) :
+                "Fail to free the memory block by PMem Memory Allocator";
+        PersistentMemoryPlatform.freeMemory(memory.getBaseOffset());
+    }
+}
diff --git a/core/pom.xml b/core/pom.xml
index 4f12d7ae3f65..76aadabca912 100644
--- a/core/pom.xml
+++ b/core/pom.xml
@@ -33,6 +33,10 @@
   <name>Spark Project Core</name>
   <url>http://spark.apache.org/</url>
   <dependencies>
+    <dependency>
+      <groupId>com.intel</groupId>
+      <artifactId>oap-common</artifactId>
+    </dependency>
     <dependency>
       <groupId>com.thoughtworks.paranamer</groupId>
       <artifactId>paranamer</artifactId>
diff --git a/core/src/main/java/org/apache/spark/memory/MemoryMode.java b/core/src/main/java/org/apache/spark/memory/MemoryMode.java
index 3a5e72d8aaec..55cccee69170 100644
--- a/core/src/main/java/org/apache/spark/memory/MemoryMode.java
+++ b/core/src/main/java/org/apache/spark/memory/MemoryMode.java
@@ -22,5 +22,6 @@
 @Private
 public enum MemoryMode {
   ON_HEAP,
-  OFF_HEAP
+  OFF_HEAP,
+  PMEM
 }
diff --git a/core/src/main/scala/org/apache/spark/SparkEnv.scala b/core/src/main/scala/org/apache/spark/SparkEnv.scala
index 72123f223253..90ca2419790b 100644
--- a/core/src/main/scala/org/apache/spark/SparkEnv.scala
+++ b/core/src/main/scala/org/apache/spark/SparkEnv.scala
@@ -25,6 +25,7 @@ import scala.collection.mutable
 import scala.util.Properties

 import com.google.common.collect.MapMaker
+import com.intel.oap.common.unsafe.PersistentMemoryPlatform

 import org.apache.spark.annotation.DeveloperApi
 import org.apache.spark.api.python.PythonWorkerFactory
@@ -211,6 +212,7 @@ object SparkEnv extends Logging {
     env
   }

+  // scalastyle:off
   /**
    * Helper method to create a SparkEnv for a driver or an executor.
    */
@@ -228,6 +230,29 @@ object SparkEnv extends Logging {

     val isDriver = executorId == SparkContext.DRIVER_IDENTIFIER

+    var numaNodeId = conf.getInt("spark.executor.numa.id", -1)
+    val pmemInitialPaths = conf.get("spark.memory.pmem.initial.path", "").split(",")
+    val pmemInitialSize = conf.getSizeAsBytes("spark.memory.pmem.initial.size", 0L)
+    if (!isDriver && pmemInitialPaths.size > 1) {
+      if (numaNodeId == -1) {
+        numaNodeId = executorId.toInt
+      }
+      val path = pmemInitialPaths(numaNodeId % 2)
+      val initPath = path + File.separator + s"executor_${executorId}" + File.pathSeparator
+      val file = new File(initPath)
+      if (file.exists() && file.isFile) {
+        file.delete()
+      }
+
+      if (!file.exists()) {
+        file.mkdirs()
+      }
+
+      require(file.isDirectory(), "PMem directory is required for initialization")
+      PersistentMemoryPlatform.initialize(initPath, pmemInitialSize, 0)
+      logInfo(s"Intel Optane PMem initialized with path: ${initPath}, size: ${pmemInitialSize} ")
+    }
+
     // Listener bus is only used on the driver
     if (isDriver) {
       assert(listenerBus != null, "Attempted to create driver SparkEnv with null listener bus!")
diff --git a/core/src/main/scala/org/apache/spark/memory/MemoryManager.scala b/core/src/main/scala/org/apache/spark/memory/MemoryManager.scala
index 0641adc2ab69..ea74c7c98768 100644
--- a/core/src/main/scala/org/apache/spark/memory/MemoryManager.scala
+++ b/core/src/main/scala/org/apache/spark/memory/MemoryManager.scala
@@ -48,6 +48,8 @@ private[spark] abstract class MemoryManager(
   @GuardedBy("this")
   protected val offHeapStorageMemoryPool = new StorageMemoryPool(this, MemoryMode.OFF_HEAP)
   @GuardedBy("this")
+  protected val pmemStorageMemoryPool = new StorageMemoryPool(this, MemoryMode.PMEM)
+  @GuardedBy("this")
   protected val onHeapExecutionMemoryPool = new ExecutionMemoryPool(this, MemoryMode.ON_HEAP)
   @GuardedBy("this")
   protected val offHeapExecutionMemoryPool = new ExecutionMemoryPool(this, MemoryMode.OFF_HEAP)
@@ -62,6 +64,12 @@ private[spark] abstract class MemoryManager(
   offHeapExecutionMemoryPool.incrementPoolSize(maxOffHeapMemory - offHeapStorageMemory)
   offHeapStorageMemoryPool.incrementPoolSize(offHeapStorageMemory)

+  private[this] val pmemInitialSize = conf.getSizeAsBytes("spark.memory.pmem.initial.size", 0L)
+  private[this] val pmemUsableRatio = conf.getDouble("spark.memory.pmem.usable.ratio", 1.0)
+  protected[this] val pmemStorageMemory = (pmemInitialSize * pmemUsableRatio).toLong
+
+  pmemStorageMemoryPool.incrementPoolSize(pmemStorageMemory)
+
   /**
    * Total available on heap memory for storage, in bytes. This amount can vary over time,
    * depending on the MemoryManager implementation.
@@ -75,6 +83,12 @@ private[spark] abstract class MemoryManager(
    */
   def maxOffHeapStorageMemory: Long

+  /**
+   * Total available pmem memory for storage, in bytes. This amount can vary over time,
+   * depending on the MemoryManager implementation.
+   */
+  def maxPMemStorageMemory: Long
+
   /**
    * Set the [[MemoryStore]] used by this manager to evict cached blocks.
    * This must be set after construction due to initialization ordering constraints.
@@ -82,6 +96,7 @@ private[spark] abstract class MemoryManager(
   final def setMemoryStore(store: MemoryStore): Unit = synchronized {
     onHeapStorageMemoryPool.setMemoryStore(store)
     offHeapStorageMemoryPool.setMemoryStore(store)
+    pmemStorageMemoryPool.setMemoryStore(store)
   }

   /**
@@ -148,6 +163,7 @@ private[spark] abstract class MemoryManager(
     memoryMode match {
       case MemoryMode.ON_HEAP => onHeapStorageMemoryPool.releaseMemory(numBytes)
       case MemoryMode.OFF_HEAP => offHeapStorageMemoryPool.releaseMemory(numBytes)
+      case MemoryMode.PMEM => pmemStorageMemoryPool.releaseMemory(numBytes)
     }
   }

@@ -157,6 +173,7 @@ private[spark] abstract class MemoryManager(
   final def releaseAllStorageMemory(): Unit = synchronized {
     onHeapStorageMemoryPool.releaseAllMemory()
     offHeapStorageMemoryPool.releaseAllMemory()
+    pmemStorageMemoryPool.releaseAllMemory()
   }

   /**
@@ -177,7 +194,8 @@ private[spark] abstract class MemoryManager(
    * Storage memory currently in use, in bytes.
    */
   final def storageMemoryUsed: Long = synchronized {
-    onHeapStorageMemoryPool.memoryUsed + offHeapStorageMemoryPool.memoryUsed
+    onHeapStorageMemoryPool.memoryUsed + offHeapStorageMemoryPool.memoryUsed +
+      pmemStorageMemoryPool.memoryUsed
   }

   /**
diff --git a/core/src/main/scala/org/apache/spark/memory/StaticMemoryManager.scala b/core/src/main/scala/org/apache/spark/memory/StaticMemoryManager.scala
index a6f7db0600e6..acbc3daa5254 100644
--- a/core/src/main/scala/org/apache/spark/memory/StaticMemoryManager.scala
+++ b/core/src/main/scala/org/apache/spark/memory/StaticMemoryManager.scala
@@ -57,12 +57,16 @@ private[spark] class StaticMemoryManager(

   override def maxOffHeapStorageMemory: Long = 0L

+  override def maxPMemStorageMemory: Long = 0L
+
   override def acquireStorageMemory(
       blockId: BlockId,
       numBytes: Long,
       memoryMode: MemoryMode): Boolean = synchronized {
     require(memoryMode != MemoryMode.OFF_HEAP,
       "StaticMemoryManager does not support off-heap storage memory")
+    require(memoryMode != MemoryMode.PMEM,
+      "StaticMemoryManager does not support pmem storage memory")
     if (numBytes > maxOnHeapStorageMemory) {
       // Fail fast if the block simply won't fit
       logInfo(s"Will not store $blockId as the required space ($numBytes bytes) exceeds our " +
@@ -79,6 +83,8 @@ private[spark] class StaticMemoryManager(
       memoryMode: MemoryMode): Boolean = synchronized {
     require(memoryMode != MemoryMode.OFF_HEAP,
       "StaticMemoryManager does not support off-heap unroll memory")
+    require(memoryMode != MemoryMode.PMEM,
+      "StaticMemoryManager does not support pmem unroll memory")
     val currentUnrollMemory = onHeapStorageMemoryPool.memoryStore.currentUnrollMemory
     val freeMemory = onHeapStorageMemoryPool.memoryFree
     // When unrolling, we will use all of the existing free memory, and, if necessary,
@@ -96,6 +102,8 @@ private[spark] class StaticMemoryManager(
       numBytes: Long,
       taskAttemptId: Long,
       memoryMode: MemoryMode): Long = synchronized {
+    require(memoryMode != MemoryMode.PMEM,
+      "StaticMemoryManager does not support pmem execution memory")
     memoryMode match {
       case MemoryMode.ON_HEAP => onHeapExecutionMemoryPool.acquireMemory(numBytes, taskAttemptId)
       case MemoryMode.OFF_HEAP => offHeapExecutionMemoryPool.acquireMemory(numBytes, taskAttemptId)
diff --git a/core/src/main/scala/org/apache/spark/memory/StorageMemoryPool.scala b/core/src/main/scala/org/apache/spark/memory/StorageMemoryPool.scala
index 4c6b639015a9..e645a99f41ec 100644
--- a/core/src/main/scala/org/apache/spark/memory/StorageMemoryPool.scala
+++ b/core/src/main/scala/org/apache/spark/memory/StorageMemoryPool.scala
@@ -38,6 +38,7 @@ private[memory] class StorageMemoryPool(
   private[this] val poolName: String = memoryMode match {
     case MemoryMode.ON_HEAP => "on-heap storage"
     case MemoryMode.OFF_HEAP => "off-heap storage"
+    case MemoryMode.PMEM => "pmem storage"
   }

   @GuardedBy("lock")
diff --git a/core/src/main/scala/org/apache/spark/memory/UnifiedMemoryManager.scala b/core/src/main/scala/org/apache/spark/memory/UnifiedMemoryManager.scala
index 78edd2c4d7fa..642425001b64 100644
--- a/core/src/main/scala/org/apache/spark/memory/UnifiedMemoryManager.scala
+++ b/core/src/main/scala/org/apache/spark/memory/UnifiedMemoryManager.scala
@@ -59,6 +59,7 @@ private[spark] class UnifiedMemoryManager private[memory] (
     assert(onHeapExecutionMemoryPool.poolSize + onHeapStorageMemoryPool.poolSize == maxHeapMemory)
     assert(
       offHeapExecutionMemoryPool.poolSize + offHeapStorageMemoryPool.poolSize == maxOffHeapMemory)
+    assert(pmemStorageMemoryPool.poolSize == pmemStorageMemory)
   }

   assertInvariants()
@@ -71,6 +72,10 @@ private[spark] class UnifiedMemoryManager private[memory] (
     maxOffHeapMemory - offHeapExecutionMemoryPool.memoryUsed
   }

+  override def maxPMemStorageMemory: Long = synchronized {
+    pmemStorageMemory
+  }
+
   /**
    * Try to acquire up to `numBytes` of execution memory for the current task and return the
    * number of bytes obtained, or 0 if none can be allocated.
@@ -86,6 +91,7 @@ private[spark] class UnifiedMemoryManager private[memory] (
       memoryMode: MemoryMode): Long = synchronized {
     assertInvariants()
     assert(numBytes >= 0)
+    require(memoryMode != MemoryMode.PMEM, "PMem can not used as execution memory")
     val (executionPool, storagePool, storageRegionSize, maxMemory) = memoryMode match {
       case MemoryMode.ON_HEAP => (
         onHeapExecutionMemoryPool,
@@ -161,6 +167,11 @@ private[spark] class UnifiedMemoryManager private[memory] (
         offHeapExecutionMemoryPool,
         offHeapStorageMemoryPool,
         maxOffHeapStorageMemory)
+      case MemoryMode.PMEM => (
+        null,
+        pmemStorageMemoryPool,
+        maxPMemStorageMemory
+      )
     }
     if (numBytes > maxMemory) {
       // Fail fast if the block simply won't fit
@@ -169,6 +180,8 @@ private[spark] class UnifiedMemoryManager private[memory] (
       return false
     }
     if (numBytes > storagePool.memoryFree) {
+      // When in PMem mode, borrowing from execution memory or eviction will not happen
+      if (memoryMode == MemoryMode.PMEM) return false
       // There is not enough free memory in the storage pool, so try to borrow free memory from
       // the execution pool.
       val memoryBorrowedFromExecution = Math.min(executionPool.memoryFree,
diff --git a/core/src/main/scala/org/apache/spark/storage/BlockManager.scala b/core/src/main/scala/org/apache/spark/storage/BlockManager.scala
index e35dd7252124..c6b07ee8f80a 100644
--- a/core/src/main/scala/org/apache/spark/storage/BlockManager.scala
+++ b/core/src/main/scala/org/apache/spark/storage/BlockManager.scala
@@ -31,10 +31,9 @@ import scala.concurrent.duration._
 import scala.reflect.ClassTag
 import scala.util.Random
 import scala.util.control.NonFatal
-
 import com.codahale.metrics.{MetricRegistry, MetricSet}
 import com.google.common.io.CountingOutputStream
-
+import com.intel.oap.common.unsafe.PersistentMemoryPlatform
 import org.apache.spark._
 import org.apache.spark.executor.{DataReadMethod, ShuffleWriteMetrics}
 import org.apache.spark.internal.{config, Logging}
@@ -445,6 +444,7 @@ private[spark] class BlockManager(
             val allocator = level.memoryMode match {
               case MemoryMode.ON_HEAP => ByteBuffer.allocate _
               case MemoryMode.OFF_HEAP => Platform.allocateDirectBuffer _
+              case MemoryMode.PMEM => PersistentMemoryPlatform.allocateVolatileDirectBuffer _
             }
             new EncryptedBlockData(tmpFile, blockSize, conf, key).toChunkedByteBuffer(allocator)

@@ -1266,6 +1266,7 @@ private[spark] class BlockManager(
           val allocator = level.memoryMode match {
             case MemoryMode.ON_HEAP => ByteBuffer.allocate _
             case MemoryMode.OFF_HEAP => Platform.allocateDirectBuffer _
+            case MemoryMode.PMEM => PersistentMemoryPlatform.allocateVolatileDirectBuffer _
           }
           val putSucceeded = memoryStore.putBytes(blockId, diskData.size, level.memoryMode, () => {
             // https://issues.apache.org/jira/browse/SPARK-6076
diff --git a/core/src/main/scala/org/apache/spark/storage/StorageLevel.scala b/core/src/main/scala/org/apache/spark/storage/StorageLevel.scala
index 4c6998d7a8e2..f31a9f137b7d 100644
--- a/core/src/main/scala/org/apache/spark/storage/StorageLevel.scala
+++ b/core/src/main/scala/org/apache/spark/storage/StorageLevel.scala
@@ -40,20 +40,23 @@ class StorageLevel private(
     private var _useDisk: Boolean,
     private var _useMemory: Boolean,
     private var _useOffHeap: Boolean,
+    private var _usePMem: Boolean,
     private var _deserialized: Boolean,
     private var _replication: Int = 1)
   extends Externalizable {

   // TODO: Also add fields for caching priority, dataset ID, and flushing.
   private def this(flags: Int, replication: Int) {
-    this((flags & 8) != 0, (flags & 4) != 0, (flags & 2) != 0, (flags & 1) != 0, replication)
+    this((flags & 16) != 0, (flags & 8) != 0, (flags & 4) != 0, (flags & 2) != 0, (flags & 1) != 0,
+      replication)
   }

-  def this() = this(false, true, false, false)  // For deserialization
+  def this() = this(false, true, false, false, false)  // For deserialization

   def useDisk: Boolean = _useDisk
   def useMemory: Boolean = _useMemory
   def useOffHeap: Boolean = _useOffHeap
+  def usePMem: Boolean = _usePMem
   def deserialized: Boolean = _deserialized
   def replication: Int = _replication

@@ -65,11 +68,12 @@ class StorageLevel private(

   private[spark] def memoryMode: MemoryMode = {
     if (useOffHeap) MemoryMode.OFF_HEAP
+    else if (usePMem) MemoryMode.PMEM
     else MemoryMode.ON_HEAP
   }

   override def clone(): StorageLevel = {
-    new StorageLevel(useDisk, useMemory, useOffHeap, deserialized, replication)
+    new StorageLevel(useDisk, useMemory, useOffHeap, usePMem, deserialized, replication)
   }

   override def equals(other: Any): Boolean = other match {
@@ -77,23 +81,27 @@ class StorageLevel private(
       s.useDisk == useDisk &&
       s.useMemory == useMemory &&
       s.useOffHeap == useOffHeap &&
+      s.usePMem == usePMem &&
       s.deserialized == deserialized &&
       s.replication == replication
     case _ =>
       false
   }

-  def isValid: Boolean = (useMemory || useDisk) && (replication > 0)
+  def isValid: Boolean = (useMemory || useDisk || usePMem) && (replication > 0)

   def toInt: Int = {
     var ret = 0
     if (_useDisk) {
-      ret |= 8
+      ret |= 16
     }
     if (_useMemory) {
-      ret |= 4
+      ret |= 8
     }
     if (_useOffHeap) {
+      ret |= 4
+    }
+    if (_usePMem) {
       ret |= 2
     }
     if (_deserialized) {
@@ -109,9 +117,10 @@ class StorageLevel private(

   override def readExternal(in: ObjectInput): Unit = Utils.tryOrIOException {
     val flags = in.readByte()
-    _useDisk = (flags & 8) != 0
-    _useMemory = (flags & 4) != 0
-    _useOffHeap = (flags & 2) != 0
+    _useDisk = (flags & 16) != 0
+    _useMemory = (flags & 8) != 0
+    _useOffHeap = (flags & 4) != 0
+    _usePMem = (flags & 2) != 0
     _deserialized = (flags & 1) != 0
     _replication = in.readByte()
   }
@@ -123,10 +132,11 @@ class StorageLevel private(
     val disk = if (useDisk) "disk" else ""
     val memory = if (useMemory) "memory" else ""
     val heap = if (useOffHeap) "offheap" else ""
+    val pmem = if (usePMem) "pmem" else ""
     val deserialize = if (deserialized) "deserialized" else ""

     val output =
-      Seq(disk, memory, heap, deserialize, s"$replication replicas").filter(_.nonEmpty)
+      Seq(disk, memory, heap, pmem, deserialize, s"$replication replicas").filter(_.nonEmpty)
     s"StorageLevel(${output.mkString(", ")})"
   }

@@ -138,6 +148,9 @@ class StorageLevel private(
     if (useMemory) {
       result += (if (useOffHeap) "Memory (off heap) " else "Memory ")
     }
+    if (usePMem) {
+      result += "PMem "
+    }
     result += (if (deserialized) "Deserialized " else "Serialized ")
     result += s"${replication}x Replicated"
     result
@@ -150,18 +163,20 @@ class StorageLevel private(
  * new storage levels.
  */
 object StorageLevel {
-  val NONE = new StorageLevel(false, false, false, false)
-  val DISK_ONLY = new StorageLevel(true, false, false, false)
-  val DISK_ONLY_2 = new StorageLevel(true, false, false, false, 2)
-  val MEMORY_ONLY = new StorageLevel(false, true, false, true)
-  val MEMORY_ONLY_2 = new StorageLevel(false, true, false, true, 2)
-  val MEMORY_ONLY_SER = new StorageLevel(false, true, false, false)
-  val MEMORY_ONLY_SER_2 = new StorageLevel(false, true, false, false, 2)
-  val MEMORY_AND_DISK = new StorageLevel(true, true, false, true)
-  val MEMORY_AND_DISK_2 = new StorageLevel(true, true, false, true, 2)
-  val MEMORY_AND_DISK_SER = new StorageLevel(true, true, false, false)
-  val MEMORY_AND_DISK_SER_2 = new StorageLevel(true, true, false, false, 2)
-  val OFF_HEAP = new StorageLevel(true, true, true, false, 1)
+  val NONE = new StorageLevel(false, false, false, false, false)
+  val DISK_ONLY = new StorageLevel(true, false, false, false, false)
+  val DISK_ONLY_2 = new StorageLevel(true, false, false, false, false, 2)
+  val MEMORY_ONLY = new StorageLevel(false, true, false, false, true)
+  val MEMORY_ONLY_2 = new StorageLevel(false, true, false, false, true, 2)
+  val MEMORY_ONLY_SER = new StorageLevel(false, true, false, false, false)
+  val MEMORY_ONLY_SER_2 = new StorageLevel(false, true, false, false, false, 2)
+  val MEMORY_AND_DISK = new StorageLevel(true, true, false, false, true)
+  val MEMORY_AND_DISK_2 = new StorageLevel(true, true, false, false, true, 2)
+  val MEMORY_AND_DISK_SER = new StorageLevel(true, true, false, false, false)
+  val MEMORY_AND_DISK_SER_2 = new StorageLevel(true, true, false, false, false, 2)
+  val OFF_HEAP = new StorageLevel(true, true, true, false, false, 1)
+  val PMEM_ONLY = new StorageLevel(false, true, false, true, false, 1)
+  val PMEM_AND_DISK = new StorageLevel(true, true, false, true, false, 1)

   /**
    * :: DeveloperApi ::
@@ -181,6 +196,8 @@ object StorageLevel {
     case "MEMORY_AND_DISK_SER" => MEMORY_AND_DISK_SER
     case "MEMORY_AND_DISK_SER_2" => MEMORY_AND_DISK_SER_2
     case "OFF_HEAP" => OFF_HEAP
+    case "PMEM_ONLY" => PMEM_ONLY
+    case "PMEM_AND_DISK" => PMEM_AND_DISK
     case _ => throw new IllegalArgumentException(s"Invalid StorageLevel: $s")
   }

@@ -196,7 +213,7 @@ object StorageLevel {
       deserialized: Boolean,
       replication: Int): StorageLevel = {
     getCachedStorageLevel(
-      new StorageLevel(useDisk, useMemory, useOffHeap, deserialized, replication))
+      new StorageLevel(useDisk, useMemory, useOffHeap, false, deserialized, replication))
   }

   /**
@@ -209,7 +226,8 @@ object StorageLevel {
       useMemory: Boolean,
       deserialized: Boolean,
       replication: Int = 1): StorageLevel = {
-    getCachedStorageLevel(new StorageLevel(useDisk, useMemory, false, deserialized, replication))
+    getCachedStorageLevel(new StorageLevel(useDisk, useMemory, false, false, deserialized,
+      replication))
   }

   /**
diff --git a/core/src/main/scala/org/apache/spark/storage/memory/MemoryStore.scala b/core/src/main/scala/org/apache/spark/storage/memory/MemoryStore.scala
index 8513359934be..4b52847b5163 100644
--- a/core/src/main/scala/org/apache/spark/storage/memory/MemoryStore.scala
+++ b/core/src/main/scala/org/apache/spark/storage/memory/MemoryStore.scala
@@ -26,6 +26,7 @@ import scala.collection.mutable.ArrayBuffer
 import scala.reflect.ClassTag

 import com.google.common.io.ByteStreams
+import com.intel.oap.common.unsafe.PersistentMemoryPlatform

 import org.apache.spark.{SparkConf, TaskContext}
 import org.apache.spark.internal.Logging
@@ -97,6 +98,9 @@ private[spark] class MemoryStore(
   // Note: off-heap unroll memory is only used in putIteratorAsBytes() because off-heap caching
   // always stores serialized values.
   private val offHeapUnrollMemoryMap = mutable.HashMap[Long, Long]()
+  // Note: pmem unroll memory is only used in putIteratorAsBytes() because off-heap caching
+  // always stores serialized values.
+  private val pmemUnrollMemoryMap = mutable.HashMap[Long, Long]()

   // Initial memory to request before unrolling any block
   private val unrollMemoryThreshold: Long =
@@ -104,7 +108,8 @@ private[spark] class MemoryStore(

   /** Total amount of memory available for storage, in bytes. */
   private def maxMemory: Long = {
-    memoryManager.maxOnHeapStorageMemory + memoryManager.maxOffHeapStorageMemory
+    memoryManager.maxOnHeapStorageMemory + memoryManager.maxOffHeapStorageMemory +
+      memoryManager.maxPMemStorageMemory
   }

   if (maxMemory < unrollMemoryThreshold) {
@@ -409,6 +414,7 @@ private[spark] class MemoryStore(
     }
     onHeapUnrollMemoryMap.clear()
     offHeapUnrollMemoryMap.clear()
+    pmemUnrollMemoryMap.clear()
     memoryManager.releaseAllStorageMemory()
     logInfo("MemoryStore cleared")
   }
@@ -555,6 +561,7 @@ private[spark] class MemoryStore(
         val unrollMemoryMap = memoryMode match {
           case MemoryMode.ON_HEAP => onHeapUnrollMemoryMap
           case MemoryMode.OFF_HEAP => offHeapUnrollMemoryMap
+          case MemoryMode.PMEM => pmemUnrollMemoryMap
         }
         unrollMemoryMap(taskAttemptId) = unrollMemoryMap.getOrElse(taskAttemptId, 0L) + memory
       }
@@ -572,6 +579,7 @@ private[spark] class MemoryStore(
       val unrollMemoryMap = memoryMode match {
         case MemoryMode.ON_HEAP => onHeapUnrollMemoryMap
         case MemoryMode.OFF_HEAP => offHeapUnrollMemoryMap
+        case MemoryMode.PMEM => pmemUnrollMemoryMap
       }
       if (unrollMemoryMap.contains(taskAttemptId)) {
         val memoryToRelease = math.min(memory, unrollMemoryMap(taskAttemptId))
@@ -590,7 +598,8 @@ private[spark] class MemoryStore(
    * Return the amount of memory currently occupied for unrolling blocks across all tasks.
    */
   def currentUnrollMemory: Long = memoryManager.synchronized {
-    onHeapUnrollMemoryMap.values.sum + offHeapUnrollMemoryMap.values.sum
+    onHeapUnrollMemoryMap.values.sum + offHeapUnrollMemoryMap.values.sum +
+      pmemUnrollMemoryMap.values.sum
   }

   /**
@@ -598,14 +607,16 @@ private[spark] class MemoryStore(
    */
   def currentUnrollMemoryForThisTask: Long = memoryManager.synchronized {
     onHeapUnrollMemoryMap.getOrElse(currentTaskAttemptId(), 0L) +
-      offHeapUnrollMemoryMap.getOrElse(currentTaskAttemptId(), 0L)
+      offHeapUnrollMemoryMap.getOrElse(currentTaskAttemptId(), 0L) +
+      pmemUnrollMemoryMap.getOrElse(currentTaskAttemptId(), 0L)
   }

   /**
    * Return the number of tasks currently unrolling blocks.
    */
   private def numTasksUnrolling: Int = memoryManager.synchronized {
-    (onHeapUnrollMemoryMap.keys ++ offHeapUnrollMemoryMap.keys).toSet.size
+    (onHeapUnrollMemoryMap.keys ++ offHeapUnrollMemoryMap.keys ++ pmemUnrollMemoryMap.keys)
+      .toSet.size
   }

   /**
@@ -693,6 +704,7 @@ private class SerializedValuesHolder[T](
   val allocator = memoryMode match {
     case MemoryMode.ON_HEAP => ByteBuffer.allocate _
     case MemoryMode.OFF_HEAP => Platform.allocateDirectBuffer _
+    case MemoryMode.PMEM => PersistentMemoryPlatform.allocateVolatileDirectBuffer _
   }

   val redirectableStream = new RedirectableOutputStream
diff --git a/core/src/test/scala/org/apache/spark/memory/TestMemoryManager.scala b/core/src/test/scala/org/apache/spark/memory/TestMemoryManager.scala
index c26945fa5fa3..83027ef7ba9d 100644
--- a/core/src/test/scala/org/apache/spark/memory/TestMemoryManager.scala
+++ b/core/src/test/scala/org/apache/spark/memory/TestMemoryManager.scala
@@ -58,6 +58,8 @@ class TestMemoryManager(conf: SparkConf)

   override def maxOffHeapStorageMemory: Long = 0L

+  override def maxPMemStorageMemory: Long = 0L
+
   private var consequentOOM = 0
   private var available = Long.MaxValue

diff --git a/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala b/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala
index d967c672c581..8479205184cc 100644
--- a/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala
+++ b/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala
@@ -237,14 +237,17 @@ class KMeans private (
       data: RDD[Vector],
       instr: Option[Instrumentation]): KMeansModel = {

-    if (data.getStorageLevel == StorageLevel.NONE) {
+    val dataStorageLevel = data.getStorageLevel
+    if (dataStorageLevel == StorageLevel.NONE) {
       logWarning("The input data is not directly cached, which may hurt performance if its"
         + " parent RDDs are also uncached.")
+    } else {
+      logDebug(s"The input data will be stored at $dataStorageLevel")
     }

     // Compute squared norms and cache them.
     val norms = data.map(Vectors.norm(_, 2.0))
-    norms.persist()
+    norms.persist(dataStorageLevel)
     val zippedData = data.zip(norms).map { case (v, norm) =>
       new VectorWithNorm(v, norm)
     }
diff --git a/pom.xml b/pom.xml
index 21f16fe00279..c1711a13a0be 100644
--- a/pom.xml
+++ b/pom.xml
@@ -109,6 +109,8 @@
   </modules>

   <properties>
+    <oap.common.version>0.8.0</oap.common.version>
+
     <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
     <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
     <java.version>1.8</java.version>
@@ -293,6 +295,11 @@
   </dependencies>
   <dependencyManagement>
     <dependencies>
+      <dependency>
+        <groupId>com.intel</groupId>
+        <artifactId>oap-common</artifactId>
+        <version>${oap.common.version}</version>
+      </dependency>
       <dependency>
         <groupId>org.apache.spark</groupId>
         <artifactId>spark-tags_${scala.binary.version}</artifactId>