diff --git a/src/main/spark2.4.4/scala/org/apache/spark/SparkEnv.scala b/src/main/spark2.4.4/scala/org/apache/spark/SparkEnv.scala
index d0217a3d24..07e16a0178 100644
--- a/src/main/spark2.4.4/scala/org/apache/spark/SparkEnv.scala
+++ b/src/main/spark2.4.4/scala/org/apache/spark/SparkEnv.scala
@@ -177,6 +177,7 @@ object SparkEnv extends Logging {
     create(
       conf,
       SparkContext.DRIVER_IDENTIFIER,
+      None,
       bindAddress,
       advertiseAddress,
       Option(port),
@@ -195,6 +196,7 @@ object SparkEnv extends Logging {
   private[spark] def createExecutorEnv(
       conf: SparkConf,
       executorId: String,
+      numaNodeId: Option[String],
       hostname: String,
       numCores: Int,
       ioEncryptionKey: Option[Array[Byte]],
@@ -202,6 +204,7 @@ object SparkEnv extends Logging {
     val env = create(
       conf,
       executorId,
+      numaNodeId,
       hostname,
       hostname,
       None,
@@ -216,9 +219,11 @@ object SparkEnv extends Logging {
   /**
    * Helper method to create a SparkEnv for a driver or an executor.
    */
+  // scalastyle:off
   private def create(
       conf: SparkConf,
       executorId: String,
+      numaNodeId: Option[String],
       bindAddress: String,
       advertiseAddress: String,
       port: Option[Int],
@@ -228,6 +233,10 @@ object SparkEnv extends Logging {
       listenerBus: LiveListenerBus = null,
       mockOutputCommitCoordinator: Option[OutputCommitCoordinator] = None): SparkEnv = {

+    // scalastyInt
+    // set Numa node id through SparkConf
+    conf.set("spark.executor.numa.id", numaNodeId.getOrElse("-1"))
+
     val isDriver = executorId == SparkContext.DRIVER_IDENTIFIER

     // Listener bus is only used on the driver
